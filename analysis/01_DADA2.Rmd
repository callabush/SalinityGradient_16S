---
title: "Infer ASVs with DADA2"
author: "Calla Bush St George"
date: "`r Sys.Date()`"
output: html_document
  toc: yes
  toc_float: 
    collapsed: no
    smooth_scroll: yes
    toc_depth: 3
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      fig.align = "center",
                      fig.path = "../figures/01_DADA2/") #Send any figure output to this folder
```

## Before you start

### Set my seed
```{r set seed}
# Any number can be chose
set.seed(567890)
```


# Goals for this file

1.  Use raw fastq and generate the quality plots to asses the quality of reads

2.  Filter and trim out bad sequences and bases from our sequencing files

3.  Write out fastq files with high quality sequences

4.  Evaluate the quality from our filter and trim.

5. Infer errors on forward and reverse reads individually

6. Identified ASVs on forward and reverse reads separately using the error model.

7. Merge forward and reverse ASVs into "contigous ASVs".

8. Generate ASV count table. (`otu_table` input for phyloseq.).



# Output that we need:

1. ASV count table: `otu_table`

2. Taxonomy table `tax_table`

3. Sample information: `sample_table` track the reads lost throughout DADA2 workflow.

## Load Libraries

```{r load-libraries}
#install.packages("devtools")
library("devtools")

#devtools::install_github("benjjneb/dada2")
library(dada2)

#install.packages("tidyverse")
library(tidyverse)
```

## Load Data

```{r load data}
#Set the raw fastq path to the raw sequencing files
#Path to the fastq files
raw_fastqs_path <- "data/01_DADA2/01_raw_gzipped_fastqs"

#What files are in this path (Intuition check)
list.files(raw_fastqs_path)

#How many files are there?
str(list.files(raw_fastqs_path))

#Create a vector of forward reads
forward_reads <- list.files(raw_fastqs_path, pattern = "R1_001.fastq.gz", full.names = TRUE) 
#Intuition check
head(forward_reads)

#Create a vector of reverse reads
reverse_reads <-list.files(raw_fastqs_path, pattern = "R2_001.fastq.gz", full.names = TRUE)
#Intuition check
head(reverse_reads)

```

## Raw Quality plots
```{r raw-quality plots}
#Randomly select 2 samples from dataset to evaluate
random_samples <- sample(1:length(forward_reads), size =2)
random_samples

#Calculate and plot quality of these two samples
plotQualityProfile(forward_reads[random_samples]) + 
  labs(title = "Forward Read Raw Quality")
plotQualityProfile(reverse_reads[random_samples]) + 
  labs(title = "Reverse Read Raw Quality")
```

## Prepare a placeholder for filtered reads

```{r prep-filtered-reads}
# vector of our samples, extract the sample information from our file
samples <- sapply(strsplit(basename(forward_reads), "_"), `[`,1)
#Intuition check
head(samples)
#place filtered reads into filtered_fastqs_path
filtered_fastqs_path <- "data/01_DADA2/02_filtered_fastqs"

# create 2 variables : filtered_F, filtered_R
filtered_forward_reads <- file.path(filtered_fastqs_path, paste0(samples, "_R1_filtered.fastq.gz"))
#Intuition check
head(filtered_forward_reads)
length(filtered_forward_reads)


filtered_reverse_reads <- file.path(filtered_fastqs_path, paste0(samples, "_R2_filtered.fastq.gz"))
#Intuition check
length(filtered_reverse_reads)
```

## Filter and Trim Reads

Parameters of filter and trim **DEPEND ON THE DATASET**

- `maxN` = number of N bases. Remove all Ns from the data. 
- `maxEE` = quality filtering threshold applied to expected errors. By default, all expected errors. Mar recommends using c(1,1). Here, if there is maxEE expected errors, its okay. If more, throw away sequence.
- `trimLeft` = trim certain number of base pairs on start of each read
- `truncQ` = truncate reads at the first instance of a quality score less than or equal to selected number. Chose 2 
- `rm.phix` = remove phi x
- `compress` = make filtered files .gzipped
- `multithread` = multithread

```{r filter-and-trim}
#Assign a vector to filtered reads
#Trim out poor bases, first three basepairs on forward reads
#Write out filtered fastq files
filtered_reads <-
  filterAndTrim(fwd = forward_reads, filt = filtered_forward_reads,
              rev = reverse_reads, filt.rev = filtered_reverse_reads,
              maxN = 0, maxEE = c(2, 2), trimLeft = 3,
              truncQ = 2, rm.phix = TRUE, compress = TRUE) #multithread = TRUE)

#These files are described in Kozich et al 2013 AEM
# Describes library prep
#Forward and reverse read have full overlap
# 515F and 806R

```

### Trimmed Quality Plots
```{r filter-trim-quality-plots}
plotQualityProfile(filtered_forward_reads[random_samples]) + 
  labs(title = "Trimmed Forward Read Quality")

plotQualityProfile(filtered_reverse_reads[random_samples]) + 
  labs(title = "Trimmed Reverse Read Quality")

```

## Aggregated Trimmed Plots
```{r aggregated-trimmed-plots}
#Aggregrate all QC plots
#Install and library patchwork
#plotQualityProfile(filtered_forward_reads, aggregate = TRUE) + 
 # plotQualityProfile(filtered_reverse_reads, aggregate = TRUE)
```

## Stats on read output from `filterAndTrim`

```{r}
#Make output into dataframe
filtered_df <- as.data.frame(filtered_reads)
head(filtered_df)

# calculate some stats
filtered_df %>%
  reframe(median_reads_in = median(reads.in),
          median_reads_out = median(reads.out),
          median_percent_retained = (median(reads.out)/median(reads.in)))

```

## Error Modeling
**NOTE:** Run separtely on each illumina dataset
```{r learn-errors}
#Forward reads
error_forward_reads <-
  learnErrors(filtered_forward_reads) # multithreade = TRUE

#Plot forward reads errors
plotErrors(error_forward_reads, nominalQ = TRUE) + labs(title = "Forward Read Error Model")

#Reverse reads
error_reverse_reads <-
  learnErrors(filtered_reverse_reads) # multithreade = TRUE

#Plot reverse reads errors
plotErrors(error_reverse_reads, nominalQ = TRUE) + labs(title = "Reverse Read Error Model")
```

## Infer ASVs

Note: this is happening separately on the forward and reverse reads. This is unique to DADA2
```{r infer-ASVs}
#Infer forward ASVs
dada_forward <- dada(filtered_forward_reads, 
                     err = error_forward_reads) # multithread = TRUE
#Infer reverse ASVs
dada_reverse <- dada(filtered_reverse_reads, 
                     err = error_reverse_reads) # multithread = TRUE
```

#Merge Forward and Reverse ASVs
```{r merge_ASVs}
# merge forward and reverse ASVs
merged_ASVs <- mergePairs(dada_forward, filtered_forward_reads, 
                          dada_reverse, filtered_reverse_reads, 
                          verbose = TRUE)

# Evaluate output
typeof(merged_ASVs)
length(merged_ASVs)
names(merged_ASVs)
```

## Generate ASV Count Table
```{r generate-ASV-table}
# Create ASV count table
raw_ASV_table <- makeSequenceTable(merged_ASVs)

#Write out the file to data/01_DADA2
```




##Session information
```{r session-info}
#Ensure reproducibility
devtools::session_info()
```



